{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-silico Pairwise Gene Regulatory Network Inference with Pre-trained Tabula\n",
    "\n",
    "In this tutorial, we illustrate the zero-shot steps for the downstream task in-silico pairwise gene regulatory network inference.\n",
    "\n",
    "Here we take Cardiogenesis system as an example. Please refer to our preprint for more information regarding the dataset and the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import anndata\n",
    "import torch\n",
    "from tabula.finetune.tokenizer import GeneVocab\n",
    "from pytorch_lightning import seed_everything\n",
    "from tabula.finetune.preprocessor import get_pretrained_model, Preprocessor, check_vocab, FinetuneConfig\n",
    "from tabula.finetune.model.insilico_grn import pairwise_inference\n",
    "from tabula.finetune.dataloader import GRNDataset\n",
    "from tabula import logger\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-define parameters \n",
    "- For detailed finetuning parameters, please refer to and modify the yaml file in `params['config_path']`\n",
    "- For model weight, please download from this link: https://drive.google.com/drive/folders/19uG3hmvBZr2Zr4mWgIU-8SQ1dSg8GZuJ?usp=sharing\n",
    "- For `data_params['data_dir']`, please download the curated h5ad file for Cardiogenesis system from this link: https://drive.google.com/drive/folders/1G-y6PYaF1nTocjXYGdLz7uzQHD_SLc2v?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': 0,\n",
    "    'config_path': '../resource/finetune_framework_perturbation.yaml',\n",
    "    'save_folder': 'finetune_out/pairwise_grn/cardiogenesis/one2one/FHF',\n",
    "    'model_path': '../weight/heart.pth',\n",
    "    'device': 'cuda:0',  \n",
    "}\n",
    "\n",
    "data_params = {\n",
    "    'data_dir': '../data/GRN/cardiogenesis.h5ad',\n",
    "    'vocab_path': '../resource/vocab.json',\n",
    "    'batch_size': 128,\n",
    "    'n_workers': 4,\n",
    "    'n_bins': 51,\n",
    "    'n_hvg': 2400,\n",
    "    'data_is_raw': False,\n",
    "}\n",
    "\n",
    "pair_list = [\n",
    "    ('BMP2', 'NKX2-5', 'activate'),\n",
    "    ('NKX2-5', 'GATA4', 'activate'),\n",
    "    ('NKX2-5', 'TBX5', 'activate'),\n",
    "    ('GATA4', 'NKX2-5', 'activate'),\n",
    "    ('TBX5', 'NKX2-5', 'activate'),\n",
    "    ('TBX5', 'GATA4', 'activate'),\n",
    "    ('BMP2', 'NKX2-5', 'activate'),\n",
    "    ('TBX5', 'TBX5', 'activate'),\n",
    "]\n",
    "all_testing_genes = [k[0] for k in pair_list] + [k[1] for k in pair_list]\n",
    "all_testing_genes = list(set(all_testing_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Configuration loaded from ../resource/finetune_framework_perturbation.yaml, save finetuning result to finetune_out/pairwise_grn/cardiogenesis/one2one/FHF\n"
     ]
    }
   ],
   "source": [
    "seed_everything(params['seed'])\n",
    "os.makedirs(params['save_folder'], exist_ok=True)\n",
    "finetune_config = FinetuneConfig(seed=params['seed'], config_path=params['config_path'])\n",
    "logger.info(f'Configuration loaded from {params[\"config_path\"]}, save finetuning result to {params[\"save_folder\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Removed 9518 genes from the dataset.\n",
      "Tabula - INFO - Filtering genes by counts ...\n",
      "Tabula - INFO - Filtering cells by counts ...\n",
      "Tabula - INFO - Normalizing total counts ...\n",
      "Tabula - INFO - Subsetting highly variable genes ...\n",
      "Tabula - WARNING - No batch_key is provided, will use all cells for HVG selection.\n",
      "Tabula - INFO - Binning data ...\n",
      "Tabula - INFO - adata shape: (233, 2400)\n",
      "Tabula - INFO - Exist gene: ['GATA4', 'TBX5', 'NKX2-5', 'BMP2'] after filtering with HVG\n"
     ]
    }
   ],
   "source": [
    "adata = anndata.read_h5ad(data_params['data_dir'])\n",
    "adata, removed_gene_labels = check_vocab(adata, data_params['vocab_path'])\n",
    "vocab = GeneVocab.from_file(data_params['vocab_path'])\n",
    "logger.info(f\"Removed {len(removed_gene_labels)} genes from the dataset.\")\n",
    "\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=5,  # step 1\n",
    "    filter_cell_by_counts=5,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_params['data_is_raw'],  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=data_params['n_hvg'],  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_params['data_is_raw'] else \"cell_ranger\",\n",
    "    binning=data_params['n_bins'],  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "\n",
    "preprocessor(adata, batch_key=None)\n",
    "adata = adata[adata.obs['Progenitor Domain'] == 'FHF', :]\n",
    "\n",
    "gene_name = adata.var[\"gene_name\"].values\n",
    "finetune_config.set_model_param('in_feature', len(gene_name))\n",
    "finetune_config.set_model_param('reconstruction_out_feature', len(gene_name))\n",
    "logger.info(f'adata shape: {adata.shape}')\n",
    "\n",
    "exist_gene = [i for i in all_testing_genes if i in gene_name]\n",
    "logger.info(f\"Exist gene: {exist_gene} after filtering with HVG\")\n",
    "\n",
    "original_expression_table = adata.X.toarray()\n",
    "expression_table = adata.layers[\"X_binned\"]\n",
    "gene_ids = adata.var[\"gene_name\"].values.tolist()\n",
    "gene_vocab_ids = [vocab[gene] for gene in gene_ids]\n",
    "Grn_dataset = GRNDataset(expression_table=expression_table)\n",
    "grn_dataloader = torch.utils.data.DataLoader(\n",
    "    Grn_dataset, batch_size=data_params['batch_size'], \n",
    "    num_workers=data_params['n_workers'], shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained Tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_pl_model = get_pretrained_model(\n",
    "    finetune_config=finetune_config,\n",
    "    model_path=params['model_path'],\n",
    "    device=params['device']\n",
    ")\n",
    "tabula_pl_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_inference(\n",
    "    pair_list=pair_list,\n",
    "    evolve_epoch=10,\n",
    "    model=tabula_pl_model,\n",
    "    vocab=vocab,\n",
    "    gene_ids=gene_vocab_ids,\n",
    "    Grn_dataloader=grn_dataloader,\n",
    "    device=params['device'],\n",
    "    save_path=params['save_folder'],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sctabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
